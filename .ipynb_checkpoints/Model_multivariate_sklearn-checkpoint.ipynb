{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "korean-diameter",
   "metadata": {},
   "source": [
    "# Model 1: cup or not cup?\n",
    "\n",
    "With this model we try to predict wether it is better to use a vacuum cup to help a woman to give birth to a child, and which are the features (indicators) that could be helpful in taking this decision.\n",
    "\n",
    "__NOTE__: For the missing values in our dataset we use sklearn multivariate feature imputation (https://scikit-learn.org/stable/modules/impute.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "existing-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# ML imports\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import plot_roc_curve, roc_curve, roc_auc_score\n",
    "\n",
    "\n",
    "# Neural Network\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.compat.v2.keras.models import Sequential\n",
    "from tensorflow.compat.v2.keras.layers import Dense, Dropout\n",
    "from tensorflow.compat.v2.keras import metrics\n",
    "from tensorflow.python.compiler.mlcompute import mlcompute\n",
    "import tensorflow.compat.v2 as tf\n",
    "tf.enable_v2_behavior()\n",
    "\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "#disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unique-cricket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets loading\n",
    "VACCUM_POS = './Data/vaccum_pos.csv'\n",
    "VACCUM_NEG = './Data/vaccum_neg.csv'\n",
    "\n",
    "df_pos = pd.read_csv(VACCUM_POS)\n",
    "df_neg = pd.read_csv(VACCUM_NEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "durable-wrist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing columns that don't carry any meaning (bad file structure)\n",
    "def remove_cols(df):\n",
    "    col_to_remove = ['any neonatal adverse event.1', 'Antenatal folder no', 'Age category', 'Gravidity category', 'Parity category', 'Birth weight categorical (g)', 'Maternal illness (categorical)',\n",
    " 'Neonatal complications 4', 'duration of 2nd stage (categorical)', 'Time till delivery of baby', 'length of hospital stay categorical', '2nd stage at cs decision',\n",
    " 'Completed or failed vacuum',\n",
    " 'fully dilated to vacuum',\n",
    " 'total duration 2nd stage (min)',\n",
    " 'vacuum fail to time of delivery by c/s']\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if 'Unnamed' in col or col in col_to_remove:\n",
    "            df.drop(columns=[col], inplace=True)\n",
    "    return df\n",
    "\n",
    "#Removing \"white\" rows\n",
    "def remove_rows(df):\n",
    "    df = df[df['Antenatal folder no'].notna()]\n",
    "    return df\n",
    "    \n",
    "\n",
    "\n",
    "df_pos = remove_rows(df_pos)\n",
    "df_neg = remove_rows(df_neg)\n",
    "\n",
    "df_pos = remove_cols(df_pos)\n",
    "df_neg = remove_cols(df_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-nicaragua",
   "metadata": {},
   "source": [
    "## Data cleaning and feature preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "representative-albuquerque",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the outcome column and concatenating the two dataframes\n",
    "df_neg['vacuum_outcome'] = 0 #failure\n",
    "df_pos['vacuum_outcome'] = 1 #success\n",
    "\n",
    "df = pd.concat((df_pos, df_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-fancy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Gravidity', 'Parity', 'Previous caesarean section',\n",
       "       'Gestational Age', 'Rh status', 'RPR status', 'HIV status',\n",
       "       'Other maternal illness', 'adverse maternal outcome',\n",
       "       'maternal complication 1', 'maternal complication 2',\n",
       "       'maternal complication 3', 'length of hospital stay post-VAVD (days) ',\n",
       "       'Birth weight (g)', 'Head circumference (cm)', 'indication',\n",
       "       'Foetal distress', 'labour initiation mode',\n",
       "       'duration of 2nd stage (min)', 'station', 'caput ', 'moulding ',\n",
       "       'liquor', 'obstetric experience', 'Cup type', 'No of pulls',\n",
       "       'No of times cup slipped', 'Episiotomy', '1 minute APGAR',\n",
       "       '5 minute apgar', 'Required resuscitation',\n",
       "       'any neonatal adverse event', 'Minor adverse  neonatal outcome',\n",
       "       'Major adverse  neonatal outcome', 'Neonatal complications 1',\n",
       "       'Neonatal complications 2', 'Neonatal complications 3',\n",
       "       'vacuum_outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "difficult-glucose",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking only the columns useful for the prediction\n",
    "useful_columns = ['Age', 'Gravidity', 'Parity', 'Previous caesarean section',\n",
    "           'Gestational Age', 'RPR status', 'HIV status',\n",
    "           'Other maternal illness', 'Head circumference (cm)', 'labour initiation mode', 'obstetric experience', 'vacuum_outcome', 'indication', 'Foetal distress', 'station', 'liquor', 'Episiotomy']\n",
    "\n",
    "df = df[useful_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cognitive-closer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing \".\" with np.nan\n",
    "df.replace(\".\", np.nan, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "exotic-denmark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gravidity</th>\n",
       "      <th>Parity</th>\n",
       "      <th>Previous caesarean section</th>\n",
       "      <th>Gestational Age</th>\n",
       "      <th>RPR status</th>\n",
       "      <th>HIV status</th>\n",
       "      <th>Other maternal illness</th>\n",
       "      <th>Head circumference (cm)</th>\n",
       "      <th>labour initiation mode</th>\n",
       "      <th>obstetric experience</th>\n",
       "      <th>vacuum_outcome</th>\n",
       "      <th>indication</th>\n",
       "      <th>Foetal distress</th>\n",
       "      <th>station</th>\n",
       "      <th>liquor</th>\n",
       "      <th>Episiotomy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>term</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>none</td>\n",
       "      <td>35</td>\n",
       "      <td>spontaneous</td>\n",
       "      <td>Obstetric diploma</td>\n",
       "      <td>1</td>\n",
       "      <td>prolonged second stage</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clear</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>term</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>none</td>\n",
       "      <td>34</td>\n",
       "      <td>spontaneous</td>\n",
       "      <td>Obstetric diploma</td>\n",
       "      <td>1</td>\n",
       "      <td>prolonged second stage</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>clear</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>term</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>chorioamnionitis</td>\n",
       "      <td>34</td>\n",
       "      <td>spontaneous</td>\n",
       "      <td>Obstetric diploma</td>\n",
       "      <td>1</td>\n",
       "      <td>foetal compromise</td>\n",
       "      <td>yes</td>\n",
       "      <td>3+</td>\n",
       "      <td>clear</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>term</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>bilharzia</td>\n",
       "      <td>33</td>\n",
       "      <td>spontaneous</td>\n",
       "      <td>MO grade 1</td>\n",
       "      <td>1</td>\n",
       "      <td>foetal compromise</td>\n",
       "      <td>yes</td>\n",
       "      <td>2+</td>\n",
       "      <td>clear</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>term</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>none</td>\n",
       "      <td>36</td>\n",
       "      <td>spontaneous</td>\n",
       "      <td>MO grade 1</td>\n",
       "      <td>1</td>\n",
       "      <td>prolonged second stage</td>\n",
       "      <td>no</td>\n",
       "      <td>1+</td>\n",
       "      <td>clear</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Gravidity  Parity Previous caesarean section Gestational Age  \\\n",
       "0  24.0        2.0     2.0                         no            term   \n",
       "1  22.0        1.0     1.0                         no            term   \n",
       "2  21.0        1.0     1.0                         no            term   \n",
       "3  21.0        1.0     1.0                         no            term   \n",
       "4  25.0        1.0     1.0                         no            term   \n",
       "\n",
       "  RPR status HIV status Other maternal illness Head circumference (cm)  \\\n",
       "0   Negative   Negative                   none                      35   \n",
       "1   Negative   Negative                   none                      34   \n",
       "2   Negative   Positive       chorioamnionitis                      34   \n",
       "3   Negative   Negative              bilharzia                      33   \n",
       "4   Negative   Negative                   none                      36   \n",
       "\n",
       "  labour initiation mode obstetric experience  vacuum_outcome  \\\n",
       "0            spontaneous    Obstetric diploma               1   \n",
       "1            spontaneous    Obstetric diploma               1   \n",
       "2            spontaneous    Obstetric diploma               1   \n",
       "3            spontaneous           MO grade 1               1   \n",
       "4            spontaneous           MO grade 1               1   \n",
       "\n",
       "               indication Foetal distress station liquor Episiotomy  \n",
       "0  prolonged second stage              no     NaN  clear         No  \n",
       "1  prolonged second stage              no       0  clear         No  \n",
       "2       foetal compromise             yes      3+  clear         No  \n",
       "3       foetal compromise             yes      2+  clear         No  \n",
       "4  prolonged second stage              no      1+  clear         No  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Showing the final dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-proposition",
   "metadata": {},
   "source": [
    "Taking care of particular columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "attractive-encyclopedia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gravidity</th>\n",
       "      <th>Parity</th>\n",
       "      <th>Previous caesarean section</th>\n",
       "      <th>Gestational Age</th>\n",
       "      <th>RPR status</th>\n",
       "      <th>HIV status</th>\n",
       "      <th>Head circumference (cm)</th>\n",
       "      <th>labour initiation mode</th>\n",
       "      <th>vacuum_outcome</th>\n",
       "      <th>indication</th>\n",
       "      <th>Foetal distress</th>\n",
       "      <th>station</th>\n",
       "      <th>liquor</th>\n",
       "      <th>Episiotomy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clear</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Gravidity  Parity  Previous caesarean section  Gestational Age  \\\n",
       "28  23.0        1.0     1.0                           0               40   \n",
       "\n",
       "   RPR status HIV status  Head circumference (cm) labour initiation mode  \\\n",
       "28          0          1                     36.0                    NaN   \n",
       "\n",
       "    vacuum_outcome indication Foetal distress station liquor Episiotomy  \n",
       "28               0        NaN             NaN     NaN  clear         no  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transforming yes/no in 1,0\n",
    "df['Previous caesarean section'] = np.where(df['Previous caesarean section'] == 'yes', 1, 0) \n",
    "\n",
    "# term -> normal gestational age (40). Then, when 'postdates' putting 42 (on average, given the data that we have, this is the most common value above 40)\n",
    "df['Gestational Age'] = np.where(df['Gestational Age'] == 'term', 40, df['Gestational Age'])\n",
    "df['Gestational Age'] = np.where(df['Gestational Age'] == 'postdates' , 42, df['Gestational Age'])\n",
    "df['Gestational Age'] = pd.to_numeric(df['Gestational Age'])\n",
    "\n",
    "# Encoding Positive to 1 and negative/Negative to 0\n",
    "df['RPR status'] = np.where(df['RPR status'] == 'Negative', 0, df['RPR status'])\n",
    "df['RPR status'] = np.where(df['RPR status'] == 'negative', 0, df['RPR status'])\n",
    "df['RPR status'] = np.where(df['RPR status'] == 'Positive', 1, df['RPR status'])\n",
    "\n",
    "# Converting Negative/negative and Positive/positive to 0 and 1\n",
    "df['HIV status'] = np.where(df['HIV status'] == 'Positive', 1, df['HIV status'])\n",
    "df['HIV status'] = np.where(df['HIV status'] == 'positive', 1, df['HIV status'])\n",
    "df['HIV status'] = np.where(df['HIV status'] == 'Negative', 0, df['HIV status'])\n",
    "df['HIV status'] = np.where(df['HIV status'] == 'negative', 0, df['HIV status'])\n",
    "\n",
    "# One hot encoding for \"Other maternal illness\". Better than mapping them to numbers.\n",
    "df = pd.get_dummies(df, prefix = ['mat_illness'], columns = ['Other maternal illness'])\n",
    "\n",
    "# Converting \"no\" in nan and the feature into integer\n",
    "df['Head circumference (cm)'] = np.where(df['Head circumference (cm)'] == 'no', np.nan, df['Head circumference (cm)'])\n",
    "df['Head circumference (cm)'] = pd.to_numeric(df['Head circumference (cm)'])\n",
    "\n",
    "# Converting spontaneous to 0 and induced to 1\n",
    "df['labour initiation mode'] = np.where(df['labour initiation mode'] == 'spontaneous', 0, df['labour initiation mode'])\n",
    "df['labour initiation mode'] = np.where(df['labour initiation mode'] == 'induced', 1, df['labour initiation mode'])\n",
    "\n",
    "# Converting same-meaning values to the same string and then performing One hot encoding\n",
    "df['obstetric experience'].replace({'obstetric diploma': 'Obstetric diploma', 'community service doctor': 'Community service doctor', 'specialist family physician': 'Specialist family physician'}, inplace = True)\n",
    "df = pd.get_dummies(df, prefix = ['obs_exp'], columns = ['obstetric experience'])\n",
    "\n",
    "# Indication has onny one NaN and then categorical values. So, to one hot encode it, we need to impute the NaN first. Apparently the most common value (220) is 'Prolonged second stage'.\n",
    "# Exploring the datapoint we see the following:\n",
    "df[df['indication'].isna()][['Age', 'Gravidity', 'Parity', 'Previous caesarean section',\n",
    "       'Gestational Age', 'RPR status', 'HIV status',\n",
    "       'Head circumference (cm)', 'labour initiation mode', 'vacuum_outcome',\n",
    "       'indication', 'Foetal distress', 'station', 'liquor', 'Episiotomy',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "incorporated-trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have NaN values for a lot of columns here -> we drop the datapoint, then we encode the feature with one-hot encoding\n",
    "df = df[~df['indication'].isna()]\n",
    "df = pd.get_dummies(df, prefix = ['indication'], columns = ['indication'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "challenging-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Foetal distress: we have \"not recorded\" which can be interpreted as NaN, and then only no and yes -> replacing \"Not recorded\" w/ NaN and then encoding it\n",
    "df['Foetal distress'] = np.where(df['Foetal distress'] == 'not recorded', np.nan, df['Foetal distress'])\n",
    "df['Foetal distress'] = np.where(df['Foetal distress'] == 'no', 0, df['Foetal distress'])\n",
    "df['Foetal distress'] = np.where(df['Foetal distress'] == 'yes', 1, df['Foetal distress'])\n",
    "\n",
    "# Station: many NaN values, and the others are categorical. So we can't drop all the datapoints for which the feature is NaN -> one hot encoding propagating the NaN to all the dummy columns when present\n",
    "df = pd.get_dummies(df, prefix =['station'], columns = ['station'], dummy_na=True)\n",
    "df.loc[df.station_nan == 1, ['station_0', 'station_1+', 'station_1-', \n",
    "                             'station_2+', 'station_2-', 'station_3+', \n",
    "                             'station_3-', 'station_outlet']] = np.nan\n",
    "df.drop(columns = ['station_nan'], inplace = True)\n",
    "\n",
    "# Same situation for the feature liquor\n",
    "df = pd.get_dummies(df, prefix =['liquor'], columns = ['liquor'], dummy_na=True)\n",
    "df.loc[df.liquor_nan == 1, ['liquor_clear', 'liquor_MSL grade 2', 'liquor_MSL grade 3', \n",
    "                             'liquor_MSL grade 1']] = np.nan\n",
    "df.drop(columns = ['liquor_nan'], inplace = True)\n",
    "\n",
    "# Episiotomt can take \"no\", \"No\", \"yes\", \"Yes\" and Nan. Converting it to a binary feature\n",
    "df['Episiotomy'] = np.where(df['Episiotomy'] == 'No', 0, df['Episiotomy'])\n",
    "df['Episiotomy'] = np.where(df['Episiotomy'] == 'no', 0, df['Episiotomy'])\n",
    "df['Episiotomy'] = np.where(df['Episiotomy'] == 'Yes', 1, df['Episiotomy'])\n",
    "df['Episiotomy'] = np.where(df['Episiotomy'] == 'yes', 1, df['Episiotomy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sensitive-class",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Gravidity', 'Parity', 'Previous caesarean section',\n",
       "       'Gestational Age', 'RPR status', 'HIV status',\n",
       "       'Head circumference (cm)', 'labour initiation mode', 'vacuum_outcome',\n",
       "       'Foetal distress', 'Episiotomy', 'mat_illness_bilharzia',\n",
       "       'mat_illness_chorioamnionitis', 'mat_illness_eclampsia',\n",
       "       'mat_illness_gestational diabetes', 'mat_illness_none',\n",
       "       'mat_illness_other', 'mat_illness_pre-eclampsia',\n",
       "       'mat_illness_pregnancy-induced hypertension',\n",
       "       'mat_illness_severe anaemia', 'mat_illness_severe pre-eclampsia',\n",
       "       'obs_exp_Community service doctor', 'obs_exp_MO grade 1',\n",
       "       'obs_exp_MO grade 2', 'obs_exp_Obstetric diploma',\n",
       "       'obs_exp_Registered midwife', 'obs_exp_Specialist family physician',\n",
       "       'obs_exp_family medicine registrar', 'indication_eclampsia',\n",
       "       'indication_foetal compromise', 'indication_maternal fatigue',\n",
       "       'indication_other', 'indication_prolonged second stage', 'station_0',\n",
       "       'station_1+', 'station_1-', 'station_2+', 'station_2-', 'station_3+',\n",
       "       'station_3-', 'station_outlet', 'liquor_MSL grade 1',\n",
       "       'liquor_MSL grade 2', 'liquor_MSL grade 3', 'liquor_clear'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing the final columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-privilege",
   "metadata": {},
   "source": [
    "## NaN Values: Analysis\n",
    "\n",
    "We need to understand if NaN values are missing at random or not, for each feature, to decide how to treat them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "marine-mileage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RPR status',\n",
       " 'Head circumference (cm)',\n",
       " 'Foetal distress',\n",
       " 'Episiotomy',\n",
       " 'station_0',\n",
       " 'station_1+',\n",
       " 'station_1-',\n",
       " 'station_2+',\n",
       " 'station_2-',\n",
       " 'station_3+',\n",
       " 'station_3-',\n",
       " 'station_outlet',\n",
       " 'liquor_MSL grade 1',\n",
       " 'liquor_MSL grade 2',\n",
       " 'liquor_MSL grade 3',\n",
       " 'liquor_clear']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of columns with NaN values\n",
    "df.columns[df.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dominant-semiconductor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For the dummy features, we can pick just one of them, since when there's a NaN in one, there's a NaN also in the other dummy feature for the same variable\n",
    "nan_cols = ['RPR status', 'Head circumference (cm)', 'Foetal distress', 'Episiotomy', 'station_0', 'liquor_MSL grade 1']\n",
    "feature_names = ['RPR status', 'Head circumference (cm)', 'Foetal distress', 'Episiotomy', 'Station', 'Liquor']\n",
    "\n",
    "# The idea is to plot: 1) Absolute number of NaN for each feature 2) Percentage of NaNs wrt the outcome\n",
    "nan_values = []\n",
    "for feature in nan_cols:\n",
    "    nan_values.append(df[feature].isna().sum())\n",
    "\n",
    "# Plot 1: absolute number of NaNs for each feature\n",
    "fig = plt.figure(figsize = (20, 10))\n",
    "sns.barplot(x = feature_names, y = nan_values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "velvet-rouge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(3, 2, figsize = (20, 10), constrained_layout = True)\n",
    "\n",
    "for i, feature in enumerate(nan_cols):\n",
    "    row = i//2\n",
    "    col = i%2\n",
    "    name = feature_names[i]\n",
    "    count_0 = df[(df[feature].isna()) & (df['vacuum_outcome'] == 0)].shape[0] / df[df['vacuum_outcome'] == 0].shape[0]\n",
    "    count_1 = df[(df[feature].isna()) & (df['vacuum_outcome'] == 1)].shape[0] / df[df['vacuum_outcome'] == 1].shape[0]\n",
    "    sns.barplot(x = ['Outcome = 0 (negative)', 'Outcome = 1 (positive)'], y = [count_0, count_1], ax = axs[row, col])\n",
    "    axs[row, col].set_xlabel(f\"Feature: {name}\")\n",
    "    axs[row, col].set_ylabel('Percentage')\n",
    "fig.suptitle('Percentage of NaN values wrt the outcome', fontsize=16);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-slovenia",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "We can notice that the distribution of NaN values is not balanced wrt the outcome for any of the features. However, while for `RPR status`, `Head circumference`, `Foetal Distress` and `Episiotomy` the percentage of NaN values is very low compared to the number of datapoints, for the features `Station` and `Liquor` there is a clear correlation between NaN values and outcome.\n",
    "\n",
    "- Station: more than 50% of values are NaN when the outcome is negative, only about 15% whene it's positive\n",
    "- Liquor: almost 60% of NaNs when the outcome is negative, only about 15% when it's positive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-billion",
   "metadata": {},
   "source": [
    "## Two models: dropping `Station` and `Liquor` and mantaining them\n",
    "\n",
    "We have two choices: the first one is to drop those two problematic features, the second one is to keep them and treat the missing values as \"missing at random\", trying to impute them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-telescope",
   "metadata": {},
   "source": [
    "### First dataset: dropping the problematic columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "domestic-services",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_toconsider = ['Age', 'Gravidity', 'Parity', 'Previous caesarean section',\n",
    "       'Gestational Age', 'RPR status', 'HIV status',\n",
    "       'Head circumference (cm)', 'labour initiation mode', 'vacuum_outcome',\n",
    "       'Foetal distress', 'Episiotomy', 'mat_illness_bilharzia',\n",
    "       'mat_illness_chorioamnionitis', 'mat_illness_eclampsia',\n",
    "       'mat_illness_gestational diabetes', 'mat_illness_none',\n",
    "       'mat_illness_other', 'mat_illness_pre-eclampsia',\n",
    "       'mat_illness_pregnancy-induced hypertension',\n",
    "       'mat_illness_severe anaemia', 'mat_illness_severe pre-eclampsia',\n",
    "       'obs_exp_Community service doctor', 'obs_exp_MO grade 1',\n",
    "       'obs_exp_MO grade 2', 'obs_exp_Obstetric diploma',\n",
    "       'obs_exp_Registered midwife', 'obs_exp_Specialist family physician',\n",
    "       'obs_exp_family medicine registrar', 'indication_eclampsia',\n",
    "       'indication_foetal compromise', 'indication_maternal fatigue',\n",
    "       'indication_other', 'indication_prolonged second stage', ]\n",
    "\n",
    "df_drop = df[cols_toconsider]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "facial-visiting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RPR status', 'Head circumference (cm)', 'Foetal distress', 'Episiotomy']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_cols = df_drop.columns[df_drop.isna().any()].tolist()\n",
    "nan_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-bible",
   "metadata": {},
   "source": [
    "### Multivariate feature imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "standing-fantasy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_imputation(X, cat_features):\n",
    "    imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "    X = pd.DataFrame(data = imp.fit_transform(X), columns = X.columns)\n",
    "    for cat_feature in cat_features:\n",
    "        X[cat_feature] = np.where(X[cat_feature] < 0.5, 0, 1)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "planned-michael",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_drop = df_drop.drop(columns = ['vacuum_outcome'])\n",
    "Y = df['vacuum_outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "lonely-cigarette",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gravidity</th>\n",
       "      <th>Parity</th>\n",
       "      <th>Previous caesarean section</th>\n",
       "      <th>Gestational Age</th>\n",
       "      <th>RPR status</th>\n",
       "      <th>HIV status</th>\n",
       "      <th>Head circumference (cm)</th>\n",
       "      <th>labour initiation mode</th>\n",
       "      <th>Foetal distress</th>\n",
       "      <th>...</th>\n",
       "      <th>obs_exp_MO grade 2</th>\n",
       "      <th>obs_exp_Obstetric diploma</th>\n",
       "      <th>obs_exp_Registered midwife</th>\n",
       "      <th>obs_exp_Specialist family physician</th>\n",
       "      <th>obs_exp_family medicine registrar</th>\n",
       "      <th>indication_eclampsia</th>\n",
       "      <th>indication_foetal compromise</th>\n",
       "      <th>indication_maternal fatigue</th>\n",
       "      <th>indication_other</th>\n",
       "      <th>indication_prolonged second stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>34.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>37.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>553 rows  33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Gravidity  Parity  Previous caesarean section  Gestational Age  \\\n",
       "0    24.0        2.0     2.0                         0.0             40.0   \n",
       "1    22.0        1.0     1.0                         0.0             40.0   \n",
       "2    21.0        1.0     1.0                         0.0             40.0   \n",
       "3    21.0        1.0     1.0                         0.0             40.0   \n",
       "4    25.0        1.0     1.0                         0.0             40.0   \n",
       "..    ...        ...     ...                         ...              ...   \n",
       "548  34.0        2.0     1.0                         0.0             40.0   \n",
       "549  19.0        1.0     1.0                         0.0             40.0   \n",
       "550  24.0        1.0     1.0                         0.0             40.0   \n",
       "551  37.0        4.0     4.0                         0.0             40.0   \n",
       "552  21.0        2.0     2.0                         1.0             40.0   \n",
       "\n",
       "     RPR status  HIV status  Head circumference (cm)  labour initiation mode  \\\n",
       "0             0         0.0                     35.0                     0.0   \n",
       "1             0         0.0                     34.0                     0.0   \n",
       "2             0         1.0                     34.0                     0.0   \n",
       "3             0         0.0                     33.0                     0.0   \n",
       "4             0         0.0                     36.0                     0.0   \n",
       "..          ...         ...                      ...                     ...   \n",
       "548           0         0.0                     36.0                     0.0   \n",
       "549           0         0.0                     36.0                     0.0   \n",
       "550           0         1.0                     38.0                     0.0   \n",
       "551           0         0.0                     37.0                     0.0   \n",
       "552           0         0.0                     35.0                     0.0   \n",
       "\n",
       "     Foetal distress  ...  obs_exp_MO grade 2  obs_exp_Obstetric diploma  \\\n",
       "0                  0  ...                 0.0                        1.0   \n",
       "1                  0  ...                 0.0                        1.0   \n",
       "2                  1  ...                 0.0                        1.0   \n",
       "3                  1  ...                 0.0                        0.0   \n",
       "4                  0  ...                 0.0                        0.0   \n",
       "..               ...  ...                 ...                        ...   \n",
       "548                0  ...                 0.0                        0.0   \n",
       "549                0  ...                 0.0                        0.0   \n",
       "550                1  ...                 0.0                        0.0   \n",
       "551                1  ...                 0.0                        0.0   \n",
       "552                1  ...                 0.0                        0.0   \n",
       "\n",
       "     obs_exp_Registered midwife  obs_exp_Specialist family physician  \\\n",
       "0                           0.0                                  0.0   \n",
       "1                           0.0                                  0.0   \n",
       "2                           0.0                                  0.0   \n",
       "3                           0.0                                  0.0   \n",
       "4                           0.0                                  0.0   \n",
       "..                          ...                                  ...   \n",
       "548                         0.0                                  0.0   \n",
       "549                         0.0                                  0.0   \n",
       "550                         0.0                                  1.0   \n",
       "551                         0.0                                  0.0   \n",
       "552                         0.0                                  0.0   \n",
       "\n",
       "     obs_exp_family medicine registrar  indication_eclampsia  \\\n",
       "0                                  0.0                   0.0   \n",
       "1                                  0.0                   0.0   \n",
       "2                                  0.0                   0.0   \n",
       "3                                  0.0                   0.0   \n",
       "4                                  0.0                   0.0   \n",
       "..                                 ...                   ...   \n",
       "548                                0.0                   0.0   \n",
       "549                                0.0                   0.0   \n",
       "550                                0.0                   0.0   \n",
       "551                                0.0                   0.0   \n",
       "552                                0.0                   0.0   \n",
       "\n",
       "     indication_foetal compromise  indication_maternal fatigue  \\\n",
       "0                             0.0                          0.0   \n",
       "1                             0.0                          0.0   \n",
       "2                             1.0                          0.0   \n",
       "3                             1.0                          0.0   \n",
       "4                             0.0                          0.0   \n",
       "..                            ...                          ...   \n",
       "548                           0.0                          0.0   \n",
       "549                           0.0                          1.0   \n",
       "550                           0.0                          0.0   \n",
       "551                           1.0                          0.0   \n",
       "552                           1.0                          0.0   \n",
       "\n",
       "     indication_other  indication_prolonged second stage  \n",
       "0                 0.0                                1.0  \n",
       "1                 0.0                                1.0  \n",
       "2                 0.0                                0.0  \n",
       "3                 0.0                                0.0  \n",
       "4                 0.0                                1.0  \n",
       "..                ...                                ...  \n",
       "548               0.0                                1.0  \n",
       "549               0.0                                0.0  \n",
       "550               0.0                                1.0  \n",
       "551               0.0                                0.0  \n",
       "552               0.0                                0.0  \n",
       "\n",
       "[553 rows x 33 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features_drop = ['RPR status', 'Foetal distress', 'Episiotomy']\n",
    "X_drop = null_imputation(X_drop, cat_features_drop)\n",
    "X_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-compression",
   "metadata": {},
   "source": [
    "### Second dataset: mantaining the problematic columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aerial-innocent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RPR status',\n",
       " 'Head circumference (cm)',\n",
       " 'Foetal distress',\n",
       " 'Episiotomy',\n",
       " 'station_0',\n",
       " 'station_1+',\n",
       " 'station_1-',\n",
       " 'station_2+',\n",
       " 'station_2-',\n",
       " 'station_3+',\n",
       " 'station_3-',\n",
       " 'station_outlet',\n",
       " 'liquor_MSL grade 1',\n",
       " 'liquor_MSL grade 2',\n",
       " 'liquor_MSL grade 3',\n",
       " 'liquor_clear']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_cols = df.columns[df.isna().any()].tolist()\n",
    "nan_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ordered-somerset",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mantain = df.drop(columns = ['vacuum_outcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "wireless-stanford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gravidity</th>\n",
       "      <th>Parity</th>\n",
       "      <th>Previous caesarean section</th>\n",
       "      <th>Gestational Age</th>\n",
       "      <th>RPR status</th>\n",
       "      <th>HIV status</th>\n",
       "      <th>Head circumference (cm)</th>\n",
       "      <th>labour initiation mode</th>\n",
       "      <th>Foetal distress</th>\n",
       "      <th>...</th>\n",
       "      <th>station_1-</th>\n",
       "      <th>station_2+</th>\n",
       "      <th>station_2-</th>\n",
       "      <th>station_3+</th>\n",
       "      <th>station_3-</th>\n",
       "      <th>station_outlet</th>\n",
       "      <th>liquor_MSL grade 1</th>\n",
       "      <th>liquor_MSL grade 2</th>\n",
       "      <th>liquor_MSL grade 3</th>\n",
       "      <th>liquor_clear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>34.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>37.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>553 rows  45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Gravidity  Parity  Previous caesarean section  Gestational Age  \\\n",
       "0    24.0        2.0     2.0                         0.0             40.0   \n",
       "1    22.0        1.0     1.0                         0.0             40.0   \n",
       "2    21.0        1.0     1.0                         0.0             40.0   \n",
       "3    21.0        1.0     1.0                         0.0             40.0   \n",
       "4    25.0        1.0     1.0                         0.0             40.0   \n",
       "..    ...        ...     ...                         ...              ...   \n",
       "548  34.0        2.0     1.0                         0.0             40.0   \n",
       "549  19.0        1.0     1.0                         0.0             40.0   \n",
       "550  24.0        1.0     1.0                         0.0             40.0   \n",
       "551  37.0        4.0     4.0                         0.0             40.0   \n",
       "552  21.0        2.0     2.0                         1.0             40.0   \n",
       "\n",
       "     RPR status  HIV status  Head circumference (cm)  labour initiation mode  \\\n",
       "0             0         0.0                     35.0                     0.0   \n",
       "1             0         0.0                     34.0                     0.0   \n",
       "2             0         1.0                     34.0                     0.0   \n",
       "3             0         0.0                     33.0                     0.0   \n",
       "4             0         0.0                     36.0                     0.0   \n",
       "..          ...         ...                      ...                     ...   \n",
       "548           0         0.0                     36.0                     0.0   \n",
       "549           0         0.0                     36.0                     0.0   \n",
       "550           0         1.0                     38.0                     0.0   \n",
       "551           0         0.0                     37.0                     0.0   \n",
       "552           0         0.0                     35.0                     0.0   \n",
       "\n",
       "     Foetal distress  ...  station_1-  station_2+  station_2-  station_3+  \\\n",
       "0                  0  ...           0           0           0           0   \n",
       "1                  0  ...           0           0           0           0   \n",
       "2                  1  ...           0           0           0           1   \n",
       "3                  1  ...           0           1           0           0   \n",
       "4                  0  ...           0           0           0           0   \n",
       "..               ...  ...         ...         ...         ...         ...   \n",
       "548                0  ...           1           0           0           0   \n",
       "549                0  ...           0           0           0           0   \n",
       "550                1  ...           0           0           0           0   \n",
       "551                1  ...           0           0           0           0   \n",
       "552                1  ...           0           0           0           0   \n",
       "\n",
       "     station_3-  station_outlet  liquor_MSL grade 1  liquor_MSL grade 2  \\\n",
       "0             0               0                   0                   0   \n",
       "1             0               0                   0                   0   \n",
       "2             0               0                   0                   0   \n",
       "3             0               0                   0                   0   \n",
       "4             0               0                   0                   0   \n",
       "..          ...             ...                 ...                 ...   \n",
       "548           0               0                   0                   0   \n",
       "549           0               0                   0                   0   \n",
       "550           0               0                   0                   1   \n",
       "551           0               0                   0                   0   \n",
       "552           0               0                   0                   0   \n",
       "\n",
       "     liquor_MSL grade 3  liquor_clear  \n",
       "0                     0             1  \n",
       "1                     0             1  \n",
       "2                     0             1  \n",
       "3                     0             1  \n",
       "4                     0             1  \n",
       "..                  ...           ...  \n",
       "548                   0             1  \n",
       "549                   0             1  \n",
       "550                   0             0  \n",
       "551                   0             1  \n",
       "552                   1             0  \n",
       "\n",
       "[553 rows x 45 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features_mantain= cat_features_drop + ['station_0','station_1+','station_1-','station_2+','station_2-',\n",
    "                                           'station_3+','station_3-','station_outlet','liquor_MSL grade 1',\n",
    "                                           'liquor_MSL grade 2','liquor_MSL grade 3','liquor_clear']\n",
    "X_mantain = null_imputation(X_mantain, cat_features_mantain)\n",
    "X_mantain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-subcommittee",
   "metadata": {},
   "source": [
    "### Model: Logistic Regression\n",
    "\n",
    "We finally have a dataset to work with, to feed our following models. The first model we're going to use is a simple Logistic Regression, to have a starting baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "sophisticated-folder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_pipeline(X, Y):\n",
    "\n",
    "    # Train test split. Labels are not balanced, thus we want the same proportion of positive/negative labels in the train and in the test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X ,Y,test_size=0.2, random_state = 42, stratify = Y)\n",
    "\n",
    "    # Scaling the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Logistic Regression cross validation & prediction\n",
    "    log_reg = LogisticRegressionCV(cv = 5, class_weight = 'balanced')\n",
    "    log_reg.fit(X_train, y_train)\n",
    "    y_pred = log_reg.predict(X_test)\n",
    "    \n",
    "    return y_pred, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fitted-element",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression on the dataset without problematic columns\n",
    "y_pred, y_test = logistic_regression_pipeline(X_drop, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "distributed-greece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.19      0.53      0.27        19\n",
      "     Class 1       0.84      0.52      0.64        92\n",
      "\n",
      "    accuracy                           0.52       111\n",
      "   macro avg       0.51      0.52      0.46       111\n",
      "weighted avg       0.73      0.52      0.58       111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names = ['Class 0', 'Class 1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-modern",
   "metadata": {},
   "source": [
    "This first model doesn't seem good. The data is not linearly separable, but this can be a good starting point. Let's try to apply the model to the complete dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "subsequent-mapping",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logistic_regression_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-10ec453eae59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Logistic regression on the dataset with problematic columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_regression_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_mantain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'logistic_regression_pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "# Logistic regression on the dataset with problematic columns\n",
    "y_pred, y_test = logistic_regression_pipeline(X_mantain, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "entire-jones",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.32      0.58      0.42        19\n",
      "     Class 1       0.90      0.75      0.82        92\n",
      "\n",
      "    accuracy                           0.72       111\n",
      "   macro avg       0.61      0.66      0.62       111\n",
      "weighted avg       0.80      0.72      0.75       111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names = ['Class 0', 'Class 1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-filing",
   "metadata": {},
   "source": [
    "### Model: Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "restricted-sailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_pipeline(X, Y):\n",
    "    # We don't need to scale the data here. Performing the split once again\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X ,Y ,test_size=0.2, random_state = 42, stratify = Y)\n",
    "\n",
    "    # Parameter for the decision tree cv\n",
    "    parameters = {'max_depth':range(3,20)}\n",
    "    clf = GridSearchCV(DecisionTreeClassifier(class_weight = 'balanced'), parameters)\n",
    "    clf.fit(X_train, y_train)\n",
    "    tree_model = clf.best_estimator_\n",
    "    y_pred = tree_model.predict(X_test)\n",
    "    \n",
    "    return y_pred, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "nasty-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree classifier on the dataset without problematic columns\n",
    "y_pred, y_test = decision_tree_pipeline(X_drop, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "curious-blame",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.25      0.37      0.30        19\n",
      "     Class 1       0.86      0.77      0.81        92\n",
      "\n",
      "    accuracy                           0.70       111\n",
      "   macro avg       0.55      0.57      0.55       111\n",
      "weighted avg       0.75      0.70      0.72       111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names = ['Class 0', 'Class 1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dietary-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree classifier on the dataset with problematic columns\n",
    "y_pred, y_test = decision_tree_pipeline(X_mantain, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "promising-origin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.24      0.37      0.29        19\n",
      "     Class 1       0.85      0.76      0.80        92\n",
      "\n",
      "    accuracy                           0.69       111\n",
      "   macro avg       0.55      0.56      0.55       111\n",
      "weighted avg       0.75      0.69      0.72       111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names = ['Class 0', 'Class 1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-denver",
   "metadata": {
    "tags": []
   },
   "source": [
    "Even a decision tree doesn't seem to be a good classifier for our purpose. In particular, it appears that class 0 (negative outcome) is hard to predict for both of our models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-shopper",
   "metadata": {},
   "source": [
    "### Model: Support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "concrete-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_pipeline(X, Y):\n",
    "\n",
    "    # Train test split. Labels are not balanced, thus we want the same proportion of positive/negative labels in the train and in the test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X ,Y,test_size=0.2, random_state = 42, stratify = Y)\n",
    "\n",
    "    # Scaling the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Logistic Regression cross validation & prediction\n",
    "    parameteres = {'C':[0.001,0.1,10,100,10e5], 'gamma':[0.1,0.01]}\n",
    "    grid = GridSearchCV(SVC(class_weight = 'balanced'), param_grid=parameteres, cv=5)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    svm_model = grid.best_estimator_\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    \n",
    "    return y_pred, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "drawn-short",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM on the dataset without problematic columns\n",
    "y_pred, y_test = svm_pipeline(X_drop, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "enabling-retirement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.18      0.16      0.17        19\n",
      "     Class 1       0.83      0.85      0.84        92\n",
      "\n",
      "    accuracy                           0.73       111\n",
      "   macro avg       0.50      0.50      0.50       111\n",
      "weighted avg       0.72      0.73      0.72       111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names = ['Class 0', 'Class 1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "political-blade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM on the dataset with problematic columns\n",
    "y_pred, y_test = svm_pipeline(X_mantain, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "vanilla-anchor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.28      0.26      0.27        19\n",
      "     Class 1       0.85      0.86      0.85        92\n",
      "\n",
      "    accuracy                           0.76       111\n",
      "   macro avg       0.56      0.56      0.56       111\n",
      "weighted avg       0.75      0.76      0.75       111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names = ['Class 0', 'Class 1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-latitude",
   "metadata": {},
   "source": [
    "### Conclusion on simple models\n",
    "\n",
    "Simple models struggle to capture dependencies between our features and the labels. In particular, the class 0 seems to be really hard to predict, even if we always use \"balanced\" as parameter for our classifiers. We now turn our attention to a simple Neural Network, to see if we achieve better results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patient-mobile",
   "metadata": {},
   "source": [
    "## A simple Neural Network for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "medium-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu instead of cpu if available and better performing\n",
    "#mlcompute.set_mlc_device(device_name='cpu')\n",
    "\n",
    "def nn_pipeline(X, Y):\n",
    "    \n",
    "    METRICS = [\n",
    "      metrics.TruePositives(name='tp'),\n",
    "      metrics.FalsePositives(name='fp'),\n",
    "      metrics.TrueNegatives(name='tn'),\n",
    "      metrics.FalseNegatives(name='fn'), \n",
    "      metrics.BinaryAccuracy(name='accuracy'),\n",
    "      metrics.Precision(name='precision'),\n",
    "      metrics.Recall(name='recall'),\n",
    "      metrics.AUC(name='auc'),]\n",
    "    \n",
    "    EPOCHS = 100\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X ,Y,test_size=0.2, random_state = 42, stratify = Y)\n",
    "    y_train = y_train.to_numpy()\n",
    "    y_test = y_test.to_numpy()\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    class_weight = compute_class_weight('balanced', classes = np.unique(y_train), y = y_train)\n",
    "    class_weight_dict = {0:class_weight[0], 1: class_weight[1]}\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim = X_train.shape[1], activation ='sigmoid'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, input_dim = X_train.shape[1], activation ='sigmoid'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics= ['accuracy'])\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs = EPOCHS, class_weight = class_weight_dict)\n",
    "    \n",
    "    y_pred = model.predict(X_test).ravel()\n",
    "    y_pred = np.where(y_pred < 0.5, 0, 1)\n",
    "    \n",
    "    return y_pred, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "broad-finger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.7002 - accuracy: 0.5982\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6731 - accuracy: 0.4699\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.7059 - accuracy: 0.5804\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.7018 - accuracy: 0.5369\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.7561 - accuracy: 0.4750\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.5296\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.7689 - accuracy: 0.4589\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6423 - accuracy: 0.6086\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6611 - accuracy: 0.6200\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.6398 - accuracy: 0.6399\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.6354 - accuracy: 0.6322\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 843us/step - loss: 0.6357 - accuracy: 0.6515\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 868us/step - loss: 0.6735 - accuracy: 0.5605\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.6380 - accuracy: 0.6223\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6547 - accuracy: 0.6545\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.6386 - accuracy: 0.6311\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.6392 - accuracy: 0.6441\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 878us/step - loss: 0.6052 - accuracy: 0.6697\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 0s 834us/step - loss: 0.6183 - accuracy: 0.6008\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.6108 - accuracy: 0.6598\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5863 - accuracy: 0.6600\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.6355 - accuracy: 0.6325\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.6339 - accuracy: 0.6222\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6403 - accuracy: 0.6226\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 778us/step - loss: 0.6115 - accuracy: 0.6491\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5766 - accuracy: 0.6838\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5552 - accuracy: 0.6704\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 0s 863us/step - loss: 0.6416 - accuracy: 0.6093\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.6043 - accuracy: 0.6382\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5658 - accuracy: 0.6982\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5618 - accuracy: 0.6733\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5899 - accuracy: 0.6223\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.6458\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5540 - accuracy: 0.6843\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 0s 997us/step - loss: 0.5790 - accuracy: 0.6605\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 0s 902us/step - loss: 0.5716 - accuracy: 0.6590\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 0s 963us/step - loss: 0.5560 - accuracy: 0.6665\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 0s 608us/step - loss: 0.5485 - accuracy: 0.6851\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.6000 - accuracy: 0.6513\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 0s 791us/step - loss: 0.5234 - accuracy: 0.7072\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5831 - accuracy: 0.6899\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.6883\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5639 - accuracy: 0.6980\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5662 - accuracy: 0.6237\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5856 - accuracy: 0.6165\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5920 - accuracy: 0.6559\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5888 - accuracy: 0.6481\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.5732 - accuracy: 0.6282\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5711 - accuracy: 0.7097\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5429 - accuracy: 0.6550\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5705 - accuracy: 0.6579\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5618 - accuracy: 0.6294\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 0s 957us/step - loss: 0.5680 - accuracy: 0.6520\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5374 - accuracy: 0.6892\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 0s 655us/step - loss: 0.5321 - accuracy: 0.6846\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5820 - accuracy: 0.6298\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 0s 961us/step - loss: 0.5477 - accuracy: 0.6801\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5820 - accuracy: 0.6738\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5918 - accuracy: 0.6471\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5929 - accuracy: 0.6555\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6035 - accuracy: 0.6762\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5735 - accuracy: 0.6547\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 0s 930us/step - loss: 0.4863 - accuracy: 0.6755\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5578 - accuracy: 0.6830\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5763 - accuracy: 0.6590\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5908 - accuracy: 0.6815\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5869 - accuracy: 0.6453\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5545 - accuracy: 0.6911\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5796 - accuracy: 0.6412\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5743 - accuracy: 0.6559\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 0s 798us/step - loss: 0.5434 - accuracy: 0.6879\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 0s 901us/step - loss: 0.5544 - accuracy: 0.6853\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 0s 978us/step - loss: 0.5677 - accuracy: 0.6454\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 0s 770us/step - loss: 0.5403 - accuracy: 0.7181\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 0s 583us/step - loss: 0.5777 - accuracy: 0.6658\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5298 - accuracy: 0.6578\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5475 - accuracy: 0.6938\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5634 - accuracy: 0.6182\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5994 - accuracy: 0.6684\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6087 - accuracy: 0.6107\n",
      "Epoch 81/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5374 - accuracy: 0.6891\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.6955\n",
      "Epoch 83/100\n",
      "14/14 [==============================] - 0s 823us/step - loss: 0.5082 - accuracy: 0.7010\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.6573\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.6825\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5150 - accuracy: 0.7036\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6107 - accuracy: 0.6613\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5422 - accuracy: 0.6838\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 0s 705us/step - loss: 0.5706 - accuracy: 0.6639\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 0s 607us/step - loss: 0.5506 - accuracy: 0.6878\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 0s 621us/step - loss: 0.5581 - accuracy: 0.6432\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.6587\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 0s 926us/step - loss: 0.5630 - accuracy: 0.6919\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5701 - accuracy: 0.6895\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5323 - accuracy: 0.6986\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5785 - accuracy: 0.6363\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.6805\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5720 - accuracy: 0.6494\n",
      "Epoch 99/100\n",
      "14/14 [==============================] - 0s 983us/step - loss: 0.6194 - accuracy: 0.6742\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 0s 757us/step - loss: 0.5280 - accuracy: 0.6510\n"
     ]
    }
   ],
   "source": [
    "# NN on the dataset without problematic columns\n",
    "y_pred, y_test = nn_pipeline(X_drop, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "hidden-hobby",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.19      0.47      0.27        19\n",
      "     Class 1       0.84      0.58      0.68        92\n",
      "\n",
      "    accuracy                           0.56       111\n",
      "   macro avg       0.51      0.52      0.48       111\n",
      "weighted avg       0.73      0.56      0.61       111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names = ['Class 0', 'Class 1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "linear-modem",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5248855835240275"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc = roc_auc_score(y_test, y_pred)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "promising-asthma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.7390 - accuracy: 0.3465\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.6367\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.6703 - accuracy: 0.5181\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 914us/step - loss: 0.6948 - accuracy: 0.5343\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.6706 - accuracy: 0.6220\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6996 - accuracy: 0.5605\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6762 - accuracy: 0.5911\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6450 - accuracy: 0.6765\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.5911 - accuracy: 0.6696\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 945us/step - loss: 0.6475 - accuracy: 0.6908\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5886 - accuracy: 0.6914\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.7223\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5729 - accuracy: 0.6697\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5124 - accuracy: 0.7543\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5675 - accuracy: 0.7360\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5318 - accuracy: 0.7606\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.7287\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4837 - accuracy: 0.7695\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5329 - accuracy: 0.7079\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.5375 - accuracy: 0.7250\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 849us/step - loss: 0.5200 - accuracy: 0.7363\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 0s 782us/step - loss: 0.5140 - accuracy: 0.7462\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 844us/step - loss: 0.4540 - accuracy: 0.7973\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 0s 704us/step - loss: 0.4921 - accuracy: 0.7810\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 639us/step - loss: 0.5272 - accuracy: 0.7566\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4368 - accuracy: 0.8040\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 0s 796us/step - loss: 0.4766 - accuracy: 0.7797\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4771 - accuracy: 0.7553\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4398 - accuracy: 0.7562\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4353 - accuracy: 0.7661\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 0s 738us/step - loss: 0.4536 - accuracy: 0.7892\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 0s 817us/step - loss: 0.4642 - accuracy: 0.7720\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 0s 812us/step - loss: 0.4772 - accuracy: 0.7741\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 0s 755us/step - loss: 0.4171 - accuracy: 0.7947\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 0s 724us/step - loss: 0.4195 - accuracy: 0.7629\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 0s 898us/step - loss: 0.4487 - accuracy: 0.8013\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 0s 830us/step - loss: 0.4271 - accuracy: 0.7963\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4639 - accuracy: 0.8024\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7830\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.7984\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5242 - accuracy: 0.7480\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.7663\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.7686\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7978\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3897 - accuracy: 0.7942\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4349 - accuracy: 0.7879\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 0s 855us/step - loss: 0.4465 - accuracy: 0.7933\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4028 - accuracy: 0.8097\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7822\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.8014\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7737\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.7831\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 0s 781us/step - loss: 0.5118 - accuracy: 0.7603\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 0s 749us/step - loss: 0.4535 - accuracy: 0.7903\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 0s 738us/step - loss: 0.4674 - accuracy: 0.7812\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 0s 617us/step - loss: 0.4077 - accuracy: 0.7758\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 0s 692us/step - loss: 0.4016 - accuracy: 0.7853\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 0s 965us/step - loss: 0.4317 - accuracy: 0.7805\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 0s 677us/step - loss: 0.3834 - accuracy: 0.8001\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4340 - accuracy: 0.8173\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4460 - accuracy: 0.7977\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.3628 - accuracy: 0.8404\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 0s 917us/step - loss: 0.4360 - accuracy: 0.8231\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 0s 979us/step - loss: 0.4015 - accuracy: 0.7915\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 0s 770us/step - loss: 0.4632 - accuracy: 0.7999\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 0s 884us/step - loss: 0.4044 - accuracy: 0.8071\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 0s 838us/step - loss: 0.3887 - accuracy: 0.8224\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 0s 905us/step - loss: 0.3975 - accuracy: 0.8235\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 0s 651us/step - loss: 0.4688 - accuracy: 0.7791\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.3752 - accuracy: 0.8050\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4332 - accuracy: 0.8163\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.3963 - accuracy: 0.8384\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4109 - accuracy: 0.8171\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 0s 727us/step - loss: 0.4362 - accuracy: 0.8093\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 0s 757us/step - loss: 0.4341 - accuracy: 0.8176\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 0s 625us/step - loss: 0.4705 - accuracy: 0.7791\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.7820\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.8018\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 0s 833us/step - loss: 0.3955 - accuracy: 0.8213\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3888 - accuracy: 0.8117\n",
      "Epoch 81/100\n",
      "14/14 [==============================] - 0s 886us/step - loss: 0.4393 - accuracy: 0.8131\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.4420 - accuracy: 0.8062\n",
      "Epoch 83/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.8046\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3814 - accuracy: 0.8138\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8261\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.8542\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 0s 905us/step - loss: 0.4775 - accuracy: 0.7809\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 0s 690us/step - loss: 0.3871 - accuracy: 0.8109\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 0s 874us/step - loss: 0.3859 - accuracy: 0.8214\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 0s 657us/step - loss: 0.4047 - accuracy: 0.8064\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 0s 1ms/step - loss: 0.3612 - accuracy: 0.8335\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 0s 639us/step - loss: 0.4103 - accuracy: 0.8403\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4891 - accuracy: 0.7723\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.8144\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7852\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4029 - accuracy: 0.8093\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 0s 973us/step - loss: 0.4298 - accuracy: 0.7915\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 0s 980us/step - loss: 0.3501 - accuracy: 0.8101\n",
      "Epoch 99/100\n",
      "14/14 [==============================] - 0s 858us/step - loss: 0.3978 - accuracy: 0.8328\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.7951\n"
     ]
    }
   ],
   "source": [
    "# NN on the dataset with problematic columns\n",
    "y_pred, y_test = nn_pipeline(X_mantain, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "super-phone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.30      0.58      0.39        19\n",
      "     Class 1       0.89      0.72      0.80        92\n",
      "\n",
      "    accuracy                           0.69       111\n",
      "   macro avg       0.59      0.65      0.59       111\n",
      "weighted avg       0.79      0.69      0.73       111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names = ['Class 0', 'Class 1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "mysterious-carter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6690503432494279"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc = roc_auc_score(y_test, y_pred)\n",
    "auc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
